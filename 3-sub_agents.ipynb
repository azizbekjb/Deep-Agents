{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450d4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from tavily import TavilyClient\n",
    "from langchain.agents import create_agent\n",
    "from deepagents import create_deep_agent, SubAgent, CompiledSubAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f6bf82",
   "metadata": {},
   "source": [
    "# Using SubAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7c62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "\n",
    "def internet_search(\n",
    "        query: str,\n",
    "        max_results: int = 5,\n",
    "        topic: Literal[\"general\", \"news\", \"finance\"] = \"general\",\n",
    "        include_raw_content: bool = False\n",
    "):\n",
    "    \"Run a web search\"\n",
    "    return tavily_client.search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        include_raw_content=include_raw_content,\n",
    "        topic=topic\n",
    "    )\n",
    "\n",
    "research_subagent = {\n",
    "    \"name\" : \"research_agent\",\n",
    "    \"description\": \"Used to research more in depth questions\",\n",
    "    \"system_prompt\": \"You are great researcher\",\n",
    "    \"tools\": [internet_search],\n",
    "    \"model\": \"google_genai:gemini-2.5-flash\",\n",
    "}\n",
    "subagets = [research_subagent]\n",
    "agent = create_deep_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",\n",
    "    subagents=subagets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c444a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: An LLM (Large Language Model) is a type of artificial intelligence program that is trained on a massive amount of text data. This allows it to understand, generate, and process human language in various ways. LLMs can perform tasks like:\n",
      "\n",
      "*   **Text generation:** Writing articles, stories, poems, code, etc.\n",
      "*   **Translation:** Translating text from one language to another.\n",
      "*   **Summarization:** Condensing long texts into shorter summaries.\n",
      "*   **Question answering:** Providing answers to questions based on its training data.\n",
      "*   **Chatbots and conversational AI:** Engaging in human-like conversations.\n",
      "\n",
      "They learn patterns, grammar, facts, and even some reasoning abilities from the vast datasets they are trained on, enabling them to produce coherent and contextually relevant responses.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is llm?\"\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\" : [\n",
    "            {\n",
    "                \"role\" : \"user\",\n",
    "                \"content\" : question\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(f\"Result: {result[\"messages\"][-1].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8301659",
   "metadata": {},
   "source": [
    "# Using CompiledSubAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ace422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom agent graph\n",
    "custom_graph = create_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",\n",
    "    tools=[internet_search],\n",
    "    system_prompt=\"You are a specialized agent for data analysis...\")\n",
    "\n",
    "# Use it as a custom subagent\n",
    "custom_subagent = CompiledSubAgent(\n",
    "    name=\"data-analyzer\",\n",
    "    description=\"Specialized agent for complex data analysis tasks\",\n",
    "    runnable=custom_graph,\n",
    ")\n",
    "\n",
    "subagets = [custom_subagent]\n",
    "\n",
    "agent = create_deep_agent(\n",
    "    model=\"google_genai:gemini-2.5-flash\",\n",
    "    tools=[internet_search],\n",
    "    system_prompt=\"Give the answer for your best practises\",\n",
    "    subagents=subagets\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a538b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      " Tavily is a company that provides a web access stack for AI agents, offering tools for real-time search, structured data extraction, and fully-rendered crawling. Their goal is to connect AI agents to the web in a way that is compliant with company-specific policies, enabling them to access and reason over live web data.\n",
      "\n",
      "Key information about Tavily:\n",
      "\n",
      "*   **Purpose:** To empower AI agents with the ability to access and utilize information from the live web.\n",
      "*   **Offerings:** Search, Extract, and Crawl APIs designed for RAG (Retrieval Augmented Generation), autonomy, and production-grade agent systems.\n",
      "*   **Funding:** They recently raised $20 million in Series A funding, led by Insight Partners.\n",
      "*   **Founded:** 2024\n",
      "*   **Company Size:** 11-50 employees\n",
      "*   **Use Cases:** Powering conversational agents, enterprise AI data analysts, and other AI applications that require up-to-date, cleaned, and structured web content.\n"
     ]
    }
   ],
   "source": [
    "question = \"Give me information about Tavily!\"\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\" : question\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Result: \\n {result[\"messages\"][-1].content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
